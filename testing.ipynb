{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from icecream import ic\n",
    "\n",
    "\n",
    "basepath = os.getcwd()\n",
    "raw_txt_dir = \"data\"\n",
    "full_path = os.path.join(basepath, raw_txt_dir)\n",
    "\n",
    "def parsefile(file):\n",
    "    try:\n",
    "        with open(file, mode=\"r\") as f:\n",
    "            contents = f.read()\n",
    "            return contents\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "\n",
    "def split_stream(stream):\n",
    "    try:\n",
    "        split_reviews = stream.split(\"\\n\")\n",
    "        review_tuples = []\n",
    "        for sent in split_reviews:\n",
    "            sent = sent.strip()\n",
    "            if sent==\"\":\n",
    "                continue\n",
    "            split_sent = sent.split(\"##\")\n",
    "            assert len(split_sent)==2, f\"This sentence review does not split into two: {sent}\"\n",
    "            split_sent[0] = split_sent[0].strip()\n",
    "            if split_sent[0] == \"\":\n",
    "                split_sent[0] = \"no_sentiment[0]\"\n",
    "            review_tuples.append((split_sent[0], split_sent[1]))\n",
    "        return review_tuples \n",
    "    except AssertionError as e:\n",
    "        print(e) \n",
    "    \n",
    "\n",
    "# def remove_annotation(stream:str) -> str:\n",
    "#     pattern = r\"\\*\\*(.*)\\*\\*\"\n",
    "#     match = re.search(pattern, stream, re.DOTALL)\n",
    "#     if match:\n",
    "#         stream = stream[:match.start()] + stream[match.end():]\n",
    "#         return stream\n",
    "#     return stream\n",
    "\n",
    "def remove_titles(stream:str) -> str:\n",
    "    pattern = r\"(\\[t\\].*)\"\n",
    "    return recurse_remove(stream=stream, pattern=pattern)\n",
    "\n",
    "def recurse_remove(stream, pattern):\n",
    "    match = re.search(pattern, stream)\n",
    "    if match is None:\n",
    "        return stream\n",
    "    else:\n",
    "        stream = stream[:match.start()] + stream[match.end():]\n",
    "        return recurse_remove(stream, pattern)\n",
    "\n",
    "def preprocess_pipeline(filepath:str) -> list[str]:\n",
    "    try:\n",
    "        raw_text = parsefile(filepath)\n",
    "        clean_of_annotations_text = remove_annotation(stream=raw_text)\n",
    "        clean_of_review_titles_text = remove_titles(stream=clean_of_annotations_text)\n",
    "        tuples = split_stream(clean_of_review_titles_text)\n",
    "        return tuples\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "\n",
    "def read_files():\n",
    "    for folder in os.listdir(full_path):\n",
    "        try:\n",
    "            for file in os.listdir(os.path.join(full_path, folder)):\n",
    "                if str(file) != \"Readme.txt\" and str(file) != \".DS_Store\":\n",
    "                    try:\n",
    "                        preprocessed_tuples = preprocess_pipeline(os.path.join(full_path, folder, file))\n",
    "                        return preprocessed_tuples\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "        except NotADirectoryError:\n",
    "            pass\n",
    "\n",
    "# path = \"/Users/jossinger/Dropbox/Studies/Bath_Artificial_Intelligence/Course Material/6_NLP/Programming/Submission/data/Reviews-9-products/norton.txt\"\n",
    "# preprocess_pipeline(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n"
     ]
    }
   ],
   "source": [
    "class Product:\n",
    "    def __init__(self, product, string):\n",
    "        self.product:str = product\n",
    "        self.reviews: list = self.parse_reviews(string)\n",
    "        self.opinions: list = []\n",
    "        self.raw_string = string\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.product}, revcount:{len(self.reviews)}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.product}, revcount:{len(self.reviews)}\"\n",
    "    \n",
    "    def parse_reviews(self, stream:str) -> list:\n",
    "        review_list: list[Review] = []\n",
    "        modified_stream: str = stream\n",
    "        # if the review is delimited by [t] symbol, break it into subsets of reviews\n",
    "        if re.search(pattern=r\"(\\[t\\])\", string=stream):\n",
    "            matches = True\n",
    "            while matches:\n",
    "                match = self.match_review_tabs(modified_stream)\n",
    "                if not match:\n",
    "                    break\n",
    "                modified_stream = modified_stream[:match.start()] + \"\\n\" + modified_stream[match.end():]\n",
    "                # remove the title from the review\n",
    "                review_string = recurse_remove(match.group(), r\"(\\[t\\].*)\")\n",
    "                review_list.append(Review(self.product, review_string))\n",
    "        else:\n",
    "            for line in modified_stream.split(\"\\n\"):\n",
    "                review_list.append(Review(self.product, line))\n",
    "        return review_list\n",
    "\n",
    "    def match_review_tabs(self, stream:str) -> re.match or None:\n",
    "        pattern = r\"(\\[t\\](.*?)(?=\\[t\\]))\"\n",
    "        match = re.search(pattern, stream, re.DOTALL)\n",
    "        if match:\n",
    "            return match\n",
    "        return None\n",
    "\n",
    "    def remove_annotation(self, stream:str) -> str:\n",
    "        pattern = r\"\\*(.*)\\*\"\n",
    "        match = re.search(pattern, stream, re.DOTALL)\n",
    "        if match:\n",
    "            stream = stream[:match.start()] + stream[match.end():]\n",
    "            return stream\n",
    "        return stream\n",
    "    \n",
    "    def recurse_remove(self, stream:str, pattern:re.Pattern)->str:\n",
    "        match = re.search(pattern, stream)\n",
    "        if match is None:\n",
    "            return stream\n",
    "        else:\n",
    "            stream = stream[:match.start()] + stream[match.end():]\n",
    "            return recurse_remove(stream, pattern)\n",
    "    \n",
    "class Review:\n",
    "    def __init__(self, product:Product, string:str):\n",
    "        self.id:str = None\n",
    "        self.product:Product = product \n",
    "        self.raw_review:str = string\n",
    "        self.sentences: list[Sentence] = []\n",
    "        self.is_single_ln = False\n",
    "\n",
    "    def split_lines(self, string):\n",
    "        lns = string.split(\"\\n\")\n",
    "        if len(lns) <= 1:\n",
    "            return [Sentence(review=self, product=self.product, string=string)]\n",
    "        else:\n",
    "            sentences = []\n",
    "            for ln in lns:\n",
    "                sentences.append(Sentence(review=self, product=self.product, string=string))\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"review: {self.raw_review}\"\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"review: {self.raw_review}\"\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, review, product, string):\n",
    "        self.id: str = None\n",
    "        self.product: Product = product\n",
    "        self.review: Review = review\n",
    "        self.raw_sentence: str = string\n",
    "        self.sentence_tuples:list[tuple] = self.split_stream(string) \n",
    "        self.user_category_scores: list = []\n",
    "        self.extracted_categories: list = []\n",
    "        \n",
    "    def split_stream(self, stream):\n",
    "        try:\n",
    "            split_reviews = stream.split(\"\\n\")\n",
    "            review_tuples = []\n",
    "            for sent in split_reviews:\n",
    "                sent = sent.strip()\n",
    "                if sent==\"\":\n",
    "                    continue\n",
    "                split_sent = sent.split(\"##\")\n",
    "                assert len(split_sent)==2, f\"This sentence review does not split into two: {sent}\"\n",
    "                split_sent[0] = split_sent[0].strip()\n",
    "                if split_sent[0] == \"\":\n",
    "                    split_sent[0] = \"no_sentiment[0]\"\n",
    "                review_tuples.append((split_sent[0], split_sent[1]))\n",
    "            return review_tuples \n",
    "        except AssertionError as e:\n",
    "            print(e) \n",
    "        \n",
    "\n",
    "paths = [\"data/CustomerReviews-3_domains/Speaker.txt\"]\n",
    "\n",
    "review_sets = []\n",
    "\n",
    "for path in paths: \n",
    "    with open(path, \"r\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
    "        stream = f.read()\n",
    "    product_name = path.split(\"/\")[-1]\n",
    "    product = Product(product_name, stream)\n",
    "    print(len(product.reviews))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/CustomerReviews-3_domains/Speaker.txt\", \"r\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
    "        stream = f.read().split('\\n')\n",
    "        print(len(stream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    for folder in os.listdir(full_path):\n",
    "        try:\n",
    "            for file in os.listdir(os.path.join(full_path, folder)):\n",
    "                if str(file) != \"Readme.txt\" and str(file) != \".DS_Store\":\n",
    "                    try:\n",
    "                        preprocessed_tuples = preprocess_pipeline(os.path.join(full_path, folder, file))\n",
    "                        return preprocessed_tuples\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "        except NotADirectoryError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = \"+2\"\n",
    "\n",
    "added = int(value) \n",
    "added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
