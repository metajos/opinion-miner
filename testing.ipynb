{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:27.056879Z",
     "start_time": "2023-12-22T12:01:27.001911Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:31.596278Z",
     "start_time": "2023-12-22T12:01:27.007179Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from opinionmining import *\n",
    "from typing import Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:31.618234Z",
     "start_time": "2023-12-22T12:01:31.605146Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jossinger/Dropbox/Studies/Bath_Artificial_Intelligence/Course Material/6_NLP/Programming/Submission/data/Reviews-9-products/norton.txt',\n",
       " '/Users/jossinger/Dropbox/Studies/Bath_Artificial_Intelligence/Course Material/6_NLP/Programming/Submission/data/Reviews-9-products/Nokia 6600.txt',\n",
       " '/Users/jossinger/Dropbox/Studies/Bath_Artificial_Intelligence/Course Material/6_NLP/Programming/Submission/data/Reviews-9-products/Hitachi router.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "for folder in os.listdir(full_path):\n",
    "    try:\n",
    "        for file in os.listdir(os.path.join(full_path, folder)):\n",
    "            if str(file) != \"Readme.txt\" and str(file) != \".DS_Store\":\n",
    "                paths.append(os.path.join(full_path, folder, file))\n",
    "    except NotADirectoryError:\n",
    "        continue\n",
    "paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:31.652593Z",
     "start_time": "2023-12-22T12:01:31.621610Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "pwd = os.getcwd()\n",
    "filename = \"db.csv\"\n",
    "if SAVE:\n",
    "    db = ReviewDatabase(paths).dataframe.to_csv(os.path.join(pwd, filename))\n",
    "else:\n",
    "    db = pd.read_csv(filename)\n",
    "\n",
    "database = db.where(db[\"Product_ID\"] == 3).copy().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:31.662237Z",
     "start_time": "2023-12-22T12:01:31.652875Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>gt_categories</th>\n",
       "      <th>gt_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>I purchased this router at a woodworking show ...</td>\n",
       "      <td>('performed',)</td>\n",
       "      <td>(2,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>Well, when I got it home and mounted it in my ...</td>\n",
       "      <td>('no sentiment',)</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>The adjustment knob seemed ok, but when loweri...</td>\n",
       "      <td>('adjustment',)</td>\n",
       "      <td>(-1,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>I tried it with the springs in and with them o...</td>\n",
       "      <td>('no sentiment',)</td>\n",
       "      <td>(0,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>The collet for the 1/4 inch bits is a pain to ...</td>\n",
       "      <td>('collet',)</td>\n",
       "      <td>(-1,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1209.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>Overall it is a great value.</td>\n",
       "      <td>('router',)</td>\n",
       "      <td>(2,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1210.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>For the price I don't think you can beat it.</td>\n",
       "      <td>('price',)</td>\n",
       "      <td>(3,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>This is a fantastic tool to use.</td>\n",
       "      <td>('tool',)</td>\n",
       "      <td>(3,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>1212.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>Only problem is that is a bit heavy.</td>\n",
       "      <td>('heavy',)</td>\n",
       "      <td>(-1,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1213.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>This is a quality product, not to be confused ...</td>\n",
       "      <td>('product',)</td>\n",
       "      <td>(1,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Product_ID  Review_ID  Sentence_ID                                           Sentence      gt_categories gt_score\n",
       "923        923.0         3.0       94.0        924.0  I purchased this router at a woodworking show ...     ('performed',)     (2,)\n",
       "924        924.0         3.0       94.0        925.0  Well, when I got it home and mounted it in my ...  ('no sentiment',)     (0,)\n",
       "925        925.0         3.0       94.0        926.0  The adjustment knob seemed ok, but when loweri...    ('adjustment',)    (-1,)\n",
       "926        926.0         3.0       94.0        927.0  I tried it with the springs in and with them o...  ('no sentiment',)     (0,)\n",
       "927        927.0         3.0       94.0        928.0  The collet for the 1/4 inch bits is a pain to ...        ('collet',)    (-1,)\n",
       "...          ...         ...        ...          ...                                                ...                ...      ...\n",
       "1209      1209.0         3.0      122.0       1210.0                       Overall it is a great value.        ('router',)     (2,)\n",
       "1210      1210.0         3.0      122.0       1211.0       For the price I don't think you can beat it.         ('price',)     (3,)\n",
       "1211      1211.0         3.0      123.0       1212.0                   This is a fantastic tool to use.          ('tool',)     (3,)\n",
       "1212      1212.0         3.0      123.0       1213.0               Only problem is that is a bit heavy.         ('heavy',)    (-1,)\n",
       "1213      1213.0         3.0      123.0       1214.0  This is a quality product, not to be confused ...       ('product',)     (1,)\n",
       "\n",
       "[291 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:34.669937Z",
     "start_time": "2023-12-22T12:01:31.664389Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>gt_categories</th>\n",
       "      <th>gt_score</th>\n",
       "      <th>ExtractedCategories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>I purchased this router at a woodworking show ...</td>\n",
       "      <td>('performed',)</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>[show, router, bits, cmt, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>Well, when I got it home and mounted it in my ...</td>\n",
       "      <td>('no sentiment',)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>[shortcomings, router, table]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>The adjustment knob seemed ok, but when loweri...</td>\n",
       "      <td>('adjustment',)</td>\n",
       "      <td>(-1,)</td>\n",
       "      <td>[knob, router, adjustment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>I tried it with the springs in and with them o...</td>\n",
       "      <td>('no sentiment',)</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>[springs, difference]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>The collet for the 1/4 inch bits is a pain to ...</td>\n",
       "      <td>('collet',)</td>\n",
       "      <td>(-1,)</td>\n",
       "      <td>[inch, collet, pain, bits]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1209.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>Overall it is a great value.</td>\n",
       "      <td>('router',)</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>[value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>1210.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>For the price I don't think you can beat it.</td>\n",
       "      <td>('price',)</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>[price]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>1211.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>This is a fantastic tool to use.</td>\n",
       "      <td>('tool',)</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>[tool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>1212.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>Only problem is that is a bit heavy.</td>\n",
       "      <td>('heavy',)</td>\n",
       "      <td>(-1,)</td>\n",
       "      <td>[problem, bit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>1213.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>This is a quality product, not to be confused ...</td>\n",
       "      <td>('product',)</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>[china, product, hitachi, junk, quality, teh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Product_ID  Review_ID  Sentence_ID                                           Sentence      gt_categories gt_score                            ExtractedCategories\n",
       "923        923.0         3.0       94.0        924.0  I purchased this router at a woodworking show ...     ('performed',)     (2,)              [show, router, bits, cmt, people]\n",
       "924        924.0         3.0       94.0        925.0  Well, when I got it home and mounted it in my ...  ('no sentiment',)     (0,)                  [shortcomings, router, table]\n",
       "925        925.0         3.0       94.0        926.0  The adjustment knob seemed ok, but when loweri...    ('adjustment',)    (-1,)                     [knob, router, adjustment]\n",
       "926        926.0         3.0       94.0        927.0  I tried it with the springs in and with them o...  ('no sentiment',)     (0,)                          [springs, difference]\n",
       "927        927.0         3.0       94.0        928.0  The collet for the 1/4 inch bits is a pain to ...        ('collet',)    (-1,)                     [inch, collet, pain, bits]\n",
       "...          ...         ...        ...          ...                                                ...                ...      ...                                            ...\n",
       "1209      1209.0         3.0      122.0       1210.0                       Overall it is a great value.        ('router',)     (2,)                                        [value]\n",
       "1210      1210.0         3.0      122.0       1211.0       For the price I don't think you can beat it.         ('price',)     (3,)                                        [price]\n",
       "1211      1211.0         3.0      123.0       1212.0                   This is a fantastic tool to use.          ('tool',)     (3,)                                         [tool]\n",
       "1212      1212.0         3.0      123.0       1213.0               Only problem is that is a bit heavy.         ('heavy',)    (-1,)                                 [problem, bit]\n",
       "1213      1213.0         3.0      123.0       1214.0  This is a quality product, not to be confused ...       ('product',)     (1,)  [china, product, hitachi, junk, quality, teh]\n",
       "\n",
       "[291 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database[\"ExtractedCategories\"] = database[\"Sentence\"].apply(lambda x : FeatureExtraction.categories(x))\n",
    "database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What is the product?\n",
    "What are the opinion categories?\n",
    "What is the sentiment of the opinion categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:39.231340Z",
     "start_time": "2023-12-22T12:01:34.688449Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a copy of the database to perform feature extraction\n",
    "category_table = database.loc[:,\"Product_ID\":\"Sentence\"].copy()\n",
    "# Perform Stemming on the sentences\n",
    "category_table[\"Stemmed_Sentence\"] = database.Sentence.apply(lambda x: FeatureExtraction.stemming([x])[0])\n",
    "# Remove the stop words\n",
    "category_table[\"Clean_Sentence\"] = category_table[\"Stemmed_Sentence\"].apply(lambda x: FeatureExtraction.remove_stop([x])[0])\n",
    "\n",
    "flattened_nouns = [item for sublist in database.ExtractedCategories for item in sublist]\n",
    "frequency_sorted_nouns = [item for item, count in Counter(flattened_nouns).most_common()]\n",
    "midpoint = len(frequency_sorted_nouns)//2\n",
    "firsthalf = frequency_sorted_nouns[:midpoint]\n",
    "secondhalf = frequency_sorted_nouns[midpoint:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The difficulty here is in mapping between effectively a many to one (through the process of stemming) to a one to one, where each category can be read as the most common form of that category.  Relies on explicitly stated product categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Use unsupervised learning to match stemmed review topics to broader content topics\n",
    "- do this by vectorizing the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:58.553518Z",
     "start_time": "2023-12-22T12:01:39.237685Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Review_ID</th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Stemmed_Sentence</th>\n",
       "      <th>Clean_Sentence</th>\n",
       "      <th>Stemmed_Transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>I purchased this router at a woodworking show ...</td>\n",
       "      <td>i purchas this router at a woodwork show after...</td>\n",
       "      <td>purchas router woodwork watch cmt peopl use de...</td>\n",
       "      <td>[shop, router, bit, bit, peopl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>Well, when I got it home and mounted it in my ...</td>\n",
       "      <td>well when i got it home and mount it in my rou...</td>\n",
       "      <td>got home mount router tabl shortcom start</td>\n",
       "      <td>[shortcom, router, tabl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>The adjustment knob seemed ok, but when loweri...</td>\n",
       "      <td>the adjust knob seem ok but when lower the rou...</td>\n",
       "      <td>adjust knob ok lower router practic pull turn ...</td>\n",
       "      <td>[job, router, adjust]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>927.0</td>\n",
       "      <td>I tried it with the springs in and with them o...</td>\n",
       "      <td>i tri it with the spring in and with them out ...</td>\n",
       "      <td>tri spring notic ani differ</td>\n",
       "      <td>[spring, differ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>3.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>The collet for the 1/4 inch bits is a pain to ...</td>\n",
       "      <td>the collet for the 1/4 inch bit is a pain to g...</td>\n",
       "      <td>collet 1/4 inch bit pain harder</td>\n",
       "      <td>[inch, collet, pain, bit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>Overall it is a great value.</td>\n",
       "      <td>overal it is a great valu</td>\n",
       "      <td>overal great valu</td>\n",
       "      <td>[valu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>For the price I don't think you can beat it.</td>\n",
       "      <td>for the price i do n't think you can beat it</td>\n",
       "      <td>price think beat</td>\n",
       "      <td>[price]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>This is a fantastic tool to use.</td>\n",
       "      <td>this is a fantast tool to use</td>\n",
       "      <td>fantast tool use</td>\n",
       "      <td>[tool]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>Only problem is that is a bit heavy.</td>\n",
       "      <td>onli problem is that is a bit heavi</td>\n",
       "      <td>onli problem bit heavi</td>\n",
       "      <td>[problem, bit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>3.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>This is a quality product, not to be confused ...</td>\n",
       "      <td>this is a qualiti product not to be confus wit...</td>\n",
       "      <td>qualiti product confus teh cheap junk hitachi ...</td>\n",
       "      <td>[china, product, hitachi, pun, qualiti, top]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Product_ID  Review_ID  Sentence_ID                                           Sentence                                   Stemmed_Sentence                                     Clean_Sentence                          Stemmed_Transactions\n",
       "923          3.0       94.0        924.0  I purchased this router at a woodworking show ...  i purchas this router at a woodwork show after...  purchas router woodwork watch cmt peopl use de...               [shop, router, bit, bit, peopl]\n",
       "924          3.0       94.0        925.0  Well, when I got it home and mounted it in my ...  well when i got it home and mount it in my rou...          got home mount router tabl shortcom start                      [shortcom, router, tabl]\n",
       "925          3.0       94.0        926.0  The adjustment knob seemed ok, but when loweri...  the adjust knob seem ok but when lower the rou...  adjust knob ok lower router practic pull turn ...                         [job, router, adjust]\n",
       "926          3.0       94.0        927.0  I tried it with the springs in and with them o...  i tri it with the spring in and with them out ...                        tri spring notic ani differ                              [spring, differ]\n",
       "927          3.0       94.0        928.0  The collet for the 1/4 inch bits is a pain to ...  the collet for the 1/4 inch bit is a pain to g...                    collet 1/4 inch bit pain harder                     [inch, collet, pain, bit]\n",
       "...          ...        ...          ...                                                ...                                                ...                                                ...                                           ...\n",
       "1209         3.0      122.0       1210.0                       Overall it is a great value.                          overal it is a great valu                                  overal great valu                                        [valu]\n",
       "1210         3.0      122.0       1211.0       For the price I don't think you can beat it.       for the price i do n't think you can beat it                                   price think beat                                       [price]\n",
       "1211         3.0      123.0       1212.0                   This is a fantastic tool to use.                      this is a fantast tool to use                                   fantast tool use                                        [tool]\n",
       "1212         3.0      123.0       1213.0               Only problem is that is a bit heavy.                onli problem is that is a bit heavi                             onli problem bit heavi                                [problem, bit]\n",
       "1213         3.0      123.0       1214.0  This is a quality product, not to be confused ...  this is a qualiti product not to be confus wit...  qualiti product confus teh cheap junk hitachi ...  [china, product, hitachi, pun, qualiti, top]\n",
       "\n",
       "[291 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = FeatureExtraction.fuzzy_match_categories(test_categories=secondhalf, target_categories=firsthalf)\n",
    "transactions = list(map(lambda x: FeatureExtraction.fuzzy_match_categories(x, D), database.ExtractedCategories))\n",
    "stemmed_transactions = list(map(lambda x: FeatureExtraction.stemming(x), transactions))\n",
    "category_table[\"Stemmed_Transactions\"] = stemmed_transactions\n",
    "item_set = [lst for lst in stemmed_transactions if len(lst) != 0]\n",
    "category_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create the stemming dictionary the remaps the stemmed words to the most commonly occuring original word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:01:58.561866Z",
     "start_time": "2023-12-22T12:01:58.554187Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemming_tuples = []\n",
    "stemming_dict = {}\n",
    "for i, l in enumerate(transactions):\n",
    "    lst = []\n",
    "    for j, word in enumerate(l):\n",
    "        original_word = word\n",
    "        stemmed_word = stemmed_transactions[i][j]\n",
    "        stemming_tuples.append((stemmed_word, original_word))\n",
    "stemming_tuples = sorted(stemming_tuples, key= lambda x: x[0])\n",
    "\n",
    "key_valuelists = {k : [] for k, v in stemming_tuples}\n",
    "for (key, value) in stemming_tuples:\n",
    "    try:\n",
    "        current_list = key_valuelists.get(key)\n",
    "        current_list.append(value)\n",
    "        key_valuelists[key] = current_list\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "#\n",
    "stemming_dict = {k: Counter(v).most_common(1)[0][0] for k, v in key_valuelists.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There is now a way to map back the stemmed features to the legible features that can be used in describing the categories so we can proceed with the apriori algorithm on the stemmed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:15:52.705570Z",
     "start_time": "2023-12-22T12:15:52.685707Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014085</td>\n",
       "      <td>(action)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063380</td>\n",
       "      <td>(adjust)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017606</td>\n",
       "      <td>(amazon)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010563</td>\n",
       "      <td>(asset)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052817</td>\n",
       "      <td>(base)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.017606</td>\n",
       "      <td>(work, tabl, router)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.010563</td>\n",
       "      <td>(spindl, tabl, work)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.010563</td>\n",
       "      <td>(height, bit, adjust, job)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.010563</td>\n",
       "      <td>(router, adjust, job, tabl)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.010563</td>\n",
       "      <td>(bit, spindl, tabl, work)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      support                     itemsets\n",
       "0    0.014085                     (action)\n",
       "1    0.063380                     (adjust)\n",
       "2    0.017606                     (amazon)\n",
       "3    0.010563                      (asset)\n",
       "4    0.052817                       (base)\n",
       "..        ...                          ...\n",
       "231  0.017606         (work, tabl, router)\n",
       "232  0.010563         (spindl, tabl, work)\n",
       "233  0.010563   (height, bit, adjust, job)\n",
       "234  0.010563  (router, adjust, job, tabl)\n",
       "235  0.010563    (bit, spindl, tabl, work)\n",
       "\n",
       "[236 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "d = item_set\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(d).transform(d)\n",
    "df = pd.DataFrame(te_ary, columns = te.columns_)\n",
    "frequent_items = apriori(df, min_support=0.01, use_colnames=True)\n",
    "frequent_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Pruning\n",
    "\n",
    "- features in the sets are not commutative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of phrases : 158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[frozenset({'adjust', 'bit'}),\n",
       " frozenset({'adjust', 'depth'}),\n",
       " frozenset({'adjust', 'height'}),\n",
       " frozenset({'adjust', 'router'}),\n",
       " frozenset({'adjust', 'tabl'}),\n",
       " frozenset({'base', 'edg'}),\n",
       " frozenset({'bit', 'chuck'}),\n",
       " frozenset({'bit', 'collet'}),\n",
       " frozenset({'bit', 'control'}),\n",
       " frozenset({'bit', 'depth'}),\n",
       " frozenset({'bit', 'diamet'}),\n",
       " frozenset({'bit', 'guid'}),\n",
       " frozenset({'bit', 'hand'}),\n",
       " frozenset({'bit', 'height'}),\n",
       " frozenset({'bit', 'inch'}),\n",
       " frozenset({'bit', 'one'}),\n",
       " frozenset({'bit', 'panel'}),\n",
       " frozenset({'bit', 'router'}),\n",
       " frozenset({'bit', 'sleev'}),\n",
       " frozenset({'bit', 'speed'}),\n",
       " frozenset({'bit', 'thing'}),\n",
       " frozenset({'bit', 'work'}),\n",
       " frozenset({'bit', 'wrench'}),\n",
       " frozenset({'chuck', 'sleev'}),\n",
       " frozenset({'control', 'motor'}),\n",
       " frozenset({'control', 'router'}),\n",
       " frozenset({'control', 'speed'}),\n",
       " frozenset({'depth', 'router'}),\n",
       " frozenset({'depth', 'scale'}),\n",
       " frozenset({'depth', 'sleev'}),\n",
       " frozenset({'edg', 'guid'}),\n",
       " frozenset({'freehand', 'router'}),\n",
       " frozenset({'hand', 'one'}),\n",
       " frozenset({'hand', 'router'}),\n",
       " frozenset({'hand', 'tabl'}),\n",
       " frozenset({'hand', 'work'}),\n",
       " frozenset({'m12', 'router'}),\n",
       " frozenset({'motor', 'speed'}),\n",
       " frozenset({'one', 'router'}),\n",
       " frozenset({'oper', 'router'}),\n",
       " frozenset({'plung', 'router'}),\n",
       " frozenset({'plung', 'tabl'}),\n",
       " frozenset({'porter', 'router'}),\n",
       " frozenset({'price', 'router'}),\n",
       " frozenset({'problem', 'router'}),\n",
       " frozenset({'raizer', 'router'}),\n",
       " frozenset({'router', 'shop'}),\n",
       " frozenset({'router', 'speed'}),\n",
       " frozenset({'router', 'start'}),\n",
       " frozenset({'router', 'tabl'}),\n",
       " frozenset({'router', 'work'}),\n",
       " frozenset({'router', 'workhors'}),\n",
       " frozenset({'speed', 'work'}),\n",
       " frozenset({'spindl', 'tabl'}),\n",
       " frozenset({'use', 'work'}),\n",
       " frozenset({'adjust', 'bit', 'height'}),\n",
       " frozenset({'adjust', 'router', 'tabl'}),\n",
       " frozenset({'bit', 'chuck', 'sleev'}),\n",
       " frozenset({'control', 'motor', 'speed'}),\n",
       " frozenset({'router', 'tabl', 'work'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doubles = []\n",
    "def get_compact_phrases(frqt_words: List[set], test_sentences: List[List[str]], max_bounds = 4, min_bounds = 2):\n",
    "    # for set check the set is within the bounds\n",
    "    for s in frqt_words:\n",
    "        if len(s) >= min_bounds and len(s) < max_bounds:\n",
    "             # get the permutations of the set of words:\n",
    "            compactness = test_compact_phrase(s, test_sentences)\n",
    "            print(f\"{compactness}\\t{s}\")\n",
    "        \n",
    "def create_permutations(frqt_set: set) -> List[list[str]]:\n",
    "    return list(itertools.permutations(frqt_set,r=len(frqt_set)))\n",
    "\n",
    "def compact_distance_between_consecutive_numbers_is_valid(lst:List[int], max_dist=3)->bool:\n",
    "     # for each permutation calculate the distance between the words, if any of the numbers are larger than 3, continue\n",
    "    for i in range(len(lst)-1):\n",
    "        if lst[i+1] - lst[i] > max_dist:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def test_compact_phrase(phrase, sentences):\n",
    "    set_words = set(phrase)\n",
    "    compact_phrase_count = 0\n",
    "    for sentence in sentences:\n",
    "        if compact_phrase_count >= 2:\n",
    "            return True\n",
    "        sentence_str = sentence.split(\" \")\n",
    "        set_sentence = set(sentence_str)\n",
    "        if set_words.issubset(set_sentence):\n",
    "            indicies = [sentence_str.index(word) for word in set_words]\n",
    "            is_compact = compact_distance_between_consecutive_numbers_is_valid(indicies)\n",
    "            if is_compact:\n",
    "                compact_phrase_count += 1\n",
    "        else:\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "    \n",
    "test_sents = list(category_table[\"Stemmed_Sentence\"])\n",
    "phrases = [phrs for phrs in frequent_items[\"itemsets\"] if len(phrs) >= 2 and len(phrs) < 4]\n",
    "single_phrases = [phrs for phrs in frequent_items[\"itemsets\"] if len(phrs) < 2]\n",
    "print(f\"# of phrases : {len(phrases)}\")\n",
    "compact_phrases = [ph for ph in phrases if test_compact_phrase(ph, test_sents)]\n",
    "compact_phrases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phrase ordering voting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrase_voting(phrases, sentences):\n",
    "    phrase_dict = {k:list(itertools.permutations(k, len(k))) for k in phrases}\n",
    "    max_perm_dict = {}\n",
    "    for k, perms in phrase_dict.items():\n",
    "        counts = [0] * len(perms)\n",
    "        for sentence in sentences:\n",
    "            sent_str = sentence.split(\" \")\n",
    "            if set(k).issubset(set(sent_str)):\n",
    "                # get the ordering of the words in the sentence\n",
    "                indexes = sorted([sent_str.index(word) for word in k if word in sent_str])\n",
    "                ordered_words = [sent_str[i] for i in indexes]\n",
    "                for i, perm in enumerate(perms):\n",
    "                    # iterate through the permutations and count the occurrence of each ordering\n",
    "                    if tuple(ordered_words) == perm:\n",
    "                        counts[i] += 1\n",
    "\n",
    "        # find the permutation with the maximum count\n",
    "        max_count_index = counts.index(max(counts))\n",
    "        max_perm_dict[k] = perms[max_count_index]\n",
    "    return max_perm_dict      \n",
    "\n",
    "\n",
    "results = phrase_voting(compact_phrases, test_sents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-support of feature `ftr` is the number of sentences that `ftr` appears in as a noun or noun phrase, and these sentences must contain no feature phrase that is a superset of `ftr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T12:33:17.025045Z",
     "start_time": "2023-12-22T12:33:17.019202Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[frozenset({'action'}),\n",
       " frozenset({'adjust'}),\n",
       " frozenset({'amazon'}),\n",
       " frozenset({'base'}),\n",
       " frozenset({'bit'}),\n",
       " frozenset({'bosch'}),\n",
       " frozenset({'chuck'}),\n",
       " frozenset({'collet'}),\n",
       " frozenset({'control'}),\n",
       " frozenset({'depth'}),\n",
       " frozenset({'edg'}),\n",
       " frozenset({'freehand'}),\n",
       " frozenset({'guid'}),\n",
       " frozenset({'hand'}),\n",
       " frozenset({'handl'}),\n",
       " frozenset({'height'}),\n",
       " frozenset({'hitachi'}),\n",
       " frozenset({'hp'}),\n",
       " frozenset({'inch'}),\n",
       " frozenset({'lock'}),\n",
       " frozenset({'machin'}),\n",
       " frozenset({'mechan'}),\n",
       " frozenset({'motor'}),\n",
       " frozenset({'one'}),\n",
       " frozenset({'oper'}),\n",
       " frozenset({'panel'}),\n",
       " frozenset({'perform'}),\n",
       " frozenset({'plenti'}),\n",
       " frozenset({'plung'}),\n",
       " frozenset({'porter'}),\n",
       " frozenset({'price'}),\n",
       " frozenset({'problem'}),\n",
       " frozenset({'qualiti'}),\n",
       " frozenset({'review'}),\n",
       " frozenset({'rout'}),\n",
       " frozenset({'router'}),\n",
       " frozenset({'shop'}),\n",
       " frozenset({'sleev'}),\n",
       " frozenset({'speed'}),\n",
       " frozenset({'spring'}),\n",
       " frozenset({'start'}),\n",
       " frozenset({'switch'}),\n",
       " frozenset({'tabl'}),\n",
       " frozenset({'thing'}),\n",
       " frozenset({'time'}),\n",
       " frozenset({'tool'}),\n",
       " frozenset({'use'}),\n",
       " frozenset({'while'}),\n",
       " frozenset({'work'}),\n",
       " frozenset({'wrench'}),\n",
       " frozenset({'adjust', 'bit'}),\n",
       " frozenset({'adjust', 'depth'}),\n",
       " frozenset({'adjust', 'height'}),\n",
       " frozenset({'adjust', 'router'}),\n",
       " frozenset({'adjust', 'tabl'}),\n",
       " frozenset({'base', 'edg'}),\n",
       " frozenset({'bit', 'chuck'}),\n",
       " frozenset({'bit', 'collet'}),\n",
       " frozenset({'bit', 'control'}),\n",
       " frozenset({'bit', 'depth'}),\n",
       " frozenset({'bit', 'diamet'}),\n",
       " frozenset({'bit', 'guid'}),\n",
       " frozenset({'bit', 'hand'}),\n",
       " frozenset({'bit', 'height'}),\n",
       " frozenset({'bit', 'inch'}),\n",
       " frozenset({'bit', 'one'}),\n",
       " frozenset({'bit', 'panel'}),\n",
       " frozenset({'bit', 'router'}),\n",
       " frozenset({'bit', 'sleev'}),\n",
       " frozenset({'bit', 'speed'}),\n",
       " frozenset({'bit', 'thing'}),\n",
       " frozenset({'bit', 'work'}),\n",
       " frozenset({'bit', 'wrench'}),\n",
       " frozenset({'chuck', 'sleev'}),\n",
       " frozenset({'control', 'motor'}),\n",
       " frozenset({'control', 'router'}),\n",
       " frozenset({'control', 'speed'}),\n",
       " frozenset({'depth', 'router'}),\n",
       " frozenset({'depth', 'scale'}),\n",
       " frozenset({'depth', 'sleev'}),\n",
       " frozenset({'edg', 'guid'}),\n",
       " frozenset({'freehand', 'router'}),\n",
       " frozenset({'hand', 'one'}),\n",
       " frozenset({'hand', 'router'}),\n",
       " frozenset({'hand', 'tabl'}),\n",
       " frozenset({'hand', 'work'}),\n",
       " frozenset({'m12', 'router'}),\n",
       " frozenset({'motor', 'speed'}),\n",
       " frozenset({'one', 'router'}),\n",
       " frozenset({'oper', 'router'}),\n",
       " frozenset({'plung', 'router'}),\n",
       " frozenset({'plung', 'tabl'}),\n",
       " frozenset({'porter', 'router'}),\n",
       " frozenset({'price', 'router'}),\n",
       " frozenset({'problem', 'router'}),\n",
       " frozenset({'raizer', 'router'}),\n",
       " frozenset({'router', 'shop'}),\n",
       " frozenset({'router', 'speed'}),\n",
       " frozenset({'router', 'start'}),\n",
       " frozenset({'router', 'tabl'}),\n",
       " frozenset({'router', 'work'}),\n",
       " frozenset({'router', 'workhors'}),\n",
       " frozenset({'speed', 'work'}),\n",
       " frozenset({'spindl', 'tabl'}),\n",
       " frozenset({'use', 'work'}),\n",
       " frozenset({'adjust', 'bit', 'height'}),\n",
       " frozenset({'adjust', 'router', 'tabl'}),\n",
       " frozenset({'bit', 'chuck', 'sleev'}),\n",
       " frozenset({'control', 'motor', 'speed'}),\n",
       " frozenset({'router', 'tabl', 'work'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_supersets(single_phrase:set, compact_phrases:List[set])->List[set]:\n",
    "    return [phrase for phrase in compact_phrases if single_phrase.issubset(compact_phrases)]\n",
    "\n",
    "def is_valid_noun(ftr, nouns):\n",
    "    for noun in nouns:\n",
    "        if ftr == noun.text:\n",
    "            return True\n",
    "    return False\n",
    "            \n",
    "\n",
    "def count_sentence(ftr, sentence, feature_phrases):\n",
    "    # count the number of times ftr appears as a noun \n",
    "    # where the sentence does not contain a feature phrase that also contains ftr\n",
    "    sentence_str = sentence.split(\" \")\n",
    "    sentence_set = set(sentence_str)\n",
    "    if ftr.issubset(sentence_set):\n",
    "        doc = nlp(sentence)\n",
    "        nouns = [token for token in doc if token.pos_ in [\"NOUN\", \"PROPN\"]]\n",
    "        # check if the noun list contains a feature phrase with the same ftr\n",
    "        super_sets = get_supersets(ftr, compact_phrases=feature_phrases)\n",
    "        if any(super for super in super_sets if ftr.issubset(super)) and not is_valid_noun(ftr, nouns):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def p_support_pruning(single_phrases:List[set], sentences:List[set], compact_phrases:List[set], threshold=3):\n",
    "    p_support = [0] * len(single_phrases)\n",
    "    for i, ftr in enumerate(single_phrases):\n",
    "        for sentence in sentences:\n",
    "            p_support[i] += count_sentence(ftr, sentence, compact_phrases)\n",
    "    return [phrase for i, phrase in enumerate(single_phrases) if p_support[i] > threshold]\n",
    "        \n",
    "reduced_single_phrases = p_support_pruning( single_phrases=single_phrases, \n",
    "                                            sentences=test_sents, \n",
    "                                            compact_phrases=compact_phrases)\n",
    "combined_features = reduced_single_phrases + compact_phrases\n",
    "combined_features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjective Extraction\n",
    "For each sentence in the review database, if it contains\n",
    "any frequent feature, extract the nearby adjective. If\n",
    "such an adjective is found, it is considered an opinion\n",
    "word. A nearby adjective refers to the adjacent\n",
    "adjective that modifies the noun/noun phrase that is a\n",
    "frequent feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('fit', 'right')},\n",
       " {('larger', 'table')},\n",
       " {('best', 'price'), ('personal', 'opinions')},\n",
       " set(),\n",
       " {('single', 'speed')},\n",
       " {('variable', 'speed')},\n",
       " {('smaller', 'retrospect')},\n",
       " {('smooth', 'cuts')},\n",
       " {('heavier', 'router')},\n",
       " set(),\n",
       " set(),\n",
       " {('great', 'price'), ('variable', 'table')},\n",
       " {('easier', 'freehand'), ('single', 'router'), ('smaller', 'bits')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('poor', 'luck')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('easy', 'change')},\n",
       " {('previous', 'reviewer')},\n",
       " set(),\n",
       " {('nice', 'table')},\n",
       " set(),\n",
       " set(),\n",
       " {('big', 'router')},\n",
       " set(),\n",
       " set(),\n",
       " {('straight', 'table')},\n",
       " set(),\n",
       " {('best', 'table')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('variable', 'control')},\n",
       " set(),\n",
       " set(),\n",
       " {('fine', 'knob'), ('parallel', 'guide')},\n",
       " {('common', 'bit')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('left', 'thumb'), ('right', 'finger'), ('straight', 'edge')},\n",
       " {('great', 'start'),\n",
       "  ('powerful', 'motor'),\n",
       "  ('soft', 'start'),\n",
       "  ('variable', 'control')},\n",
       " {('awkward', 'bit'), ('handheld', 'lock'), ('nice', 'things')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('tremendous', 'help')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('variable', 'speed')},\n",
       " set(),\n",
       " set(),\n",
       " {('flimsy', 'works')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('elated', 'decision')},\n",
       " set(),\n",
       " set(),\n",
       " {('fair', 'time')},\n",
       " set(),\n",
       " set(),\n",
       " {('micro', 'adjustment')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('accessible', 'switch')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('worth', 'tool')},\n",
       " {('excellent', 'money')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('best', 'money')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('large', 'freud')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('great', 'knob')},\n",
       " {('lower', 'table')},\n",
       " {('easy', 'change'), ('great', 'bits')},\n",
       " {('lighter', 'models')},\n",
       " set(),\n",
       " {('incredible', 'pack')},\n",
       " {('total', 'delivery')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('soft', 'start')},\n",
       " {('bad', 'models'), ('powerful', 'models')},\n",
       " {('great', 'accuracy')},\n",
       " {('large', 'table')},\n",
       " set(),\n",
       " set(),\n",
       " {('stiff', 'mechanism')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('half', 'inch')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('comfortable', 'use')},\n",
       " {('ergonomic', 'price')},\n",
       " {('professional', 'window')},\n",
       " set(),\n",
       " set(),\n",
       " {('real', 'introduction')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('fine', 'knob'), ('great', 'circumstances')},\n",
       " {('little', 'columns')},\n",
       " set(),\n",
       " set(),\n",
       " {('complete', 'routers')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('round', 'bit')},\n",
       " {('easier', 'router')},\n",
       " {('comfortable', 'experience')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('free', 'mode')},\n",
       " {('comfortable', 'jump'), ('good', 'visibility')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('plenty', 'bit')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('fine', 'adjustments')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('satisfied', 'years')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('stationary', 'table')},\n",
       " set(),\n",
       " {('critical', 'work')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('universal', 'control'), ('variable', 'speed')},\n",
       " {('flawlessly', 'capacity')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('good', 'router')},\n",
       " {('outstanding', 'performer')},\n",
       " set(),\n",
       " set(),\n",
       " {('double', 'router')},\n",
       " {('loved', 'router')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('dual', 'routers')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('great', 'tables')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('kit(simple', 'setup')},\n",
       " {('soft', 'start')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('spare', 'backup')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('excellent', 'price')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('comparible', 'makers'), ('sceptical', 'makers')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('imaginable', 'wood')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('huge', 'disapointment')},\n",
       " {('sloppy', 'adjustment')},\n",
       " set(),\n",
       " set(),\n",
       " {('impossible', 'fingers')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('skeptical', 'price')},\n",
       " {('popular', 'kit')},\n",
       " {('flat', 'edge')},\n",
       " {('beautiful', 'recessed'), ('flat', 'edge')},\n",
       " set(),\n",
       " set(),\n",
       " {('nice', 'works')},\n",
       " set(),\n",
       " {('good', 'pass'), ('negative', 'router')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('real', 'workhorse'), ('worth', 'years')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('different', 'hack')},\n",
       " {('plenty', 'power')},\n",
       " set(),\n",
       " set(),\n",
       " {('best', 'budget')},\n",
       " {('second', 'table')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('single', 'work')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('difficult', 'table')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('heavy', 'hand')},\n",
       " {('variable', 'speed')},\n",
       " {('fine', 'die')},\n",
       " set(),\n",
       " set(),\n",
       " {('easy', 'works')},\n",
       " {('big', 'deal')},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {('fantastic', 'tool')},\n",
       " {('heavy', 'problem')},\n",
       " set()]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_sets = []\n",
    "\n",
    "features = combined_features\n",
    "sentences = database.Sentence.apply(lambda x: FeatureExtraction.clean_sentence(x))\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    sentence_set = set(token.text for token in doc)\n",
    "    sentence_str = [token.text for token in doc]\n",
    "    op_words = []\n",
    "    for feature in features:\n",
    "        if feature.issubset(sentence_set):\n",
    "            feature_position = sentence_str.index(list(feature)[0])\n",
    "            adjectives = [(feature_position, feature, i, token) for i, token in enumerate(doc) if token.pos_ == \"ADJ\"]\n",
    "            op_words.append(adjectives)\n",
    "    opinion_sets.append(set([tup for op in op_words for tup in op if len(op) > 0]))\n",
    "opinion_sets\n",
    "\n",
    "def get_closest_adjective(ary_sets: Set[Tuple[int, frozenset, int, str]]) -> Set[Tuple[int, frozenset, int, str]]:\n",
    "    if len(ary_sets) == 0:\n",
    "        return set()\n",
    "    # Initialize a dictionary\n",
    "    closest_sets = {}\n",
    "    for feature_index, feature, adj_index, adj in ary_sets:\n",
    "        if feature not in closest_sets:\n",
    "            closest_sets[feature] = (float('inf'), None) \n",
    "        # Calculate distance between feature and adjective\n",
    "        distance = abs(feature_index - adj_index)\n",
    "        if distance < closest_sets[feature][0]:\n",
    "            closest_sets[feature] = (distance, (feature_index, feature, adj_index, adj))\n",
    "    # Extract the closest adjective n_ary from the dictionary\n",
    "    return set(value[1] for value in closest_sets.values() if value[1])\n",
    "\n",
    "\n",
    "infreq_opinions = []\n",
    "for i, opinion_set in enumerate(opinion_sets):\n",
    "\n",
    "    s = [t for t in nlp(sentences.to_list()[i])]\n",
    "    closest_opinion_set = get_closest_adjective(opinion_set)\n",
    "    if closest_opinion_set == set():\n",
    "        infreq_opinions.append(set())\n",
    "    op_set = set()\n",
    "    for _, feature, i_adj, adj in closest_opinion_set:\n",
    "        token = s[i_adj]\n",
    "\n",
    "        if token.text == adj.text:\n",
    "            if token.head.text in feature:\n",
    "                continue\n",
    "            if token.head.pos_ == \"NOUN\":\n",
    "                op_set.add((adj.text, token.head.text))\n",
    "            # print(f\"token_head= {token.head}, adj = {adj.text}, adj_dep = {adj.dep_}, dep={token.head.dep_}, head_pos = {token.head.pos_}\")\n",
    "    infreq_opinions.append(op_set)\n",
    "infreq_opinions\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
