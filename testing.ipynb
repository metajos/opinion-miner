{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('software[-3]',\n",
       "  'I have read the installation instructions for both NIS 2004 and NAV 2004 prior to installation, but still ended up with the same result...junk software.'),\n",
       " ('no_sentiment[0]',\n",
       "  'Why is it that I can install any other type of software and it installs and works properly?'),\n",
       " ('Norton products[-3]',\n",
       "  'But if I installed either one of these Norton products, neither works after installation?'),\n",
       " ('McAfee Anti-Virus 8[+2]]',\n",
       "  'It can not be the computer or the owner, since I purchased McAfee Anti-Virus 8 and it installs and works fine with no problems.'),\n",
       " ('Norton[-2]',\n",
       "  'I have used Norton for the past 5 years and for the last 2 years, the software has gotten more and more disgraceful.'),\n",
       " ('Norton[-2]', 'I am glad that I do not work for Norton.'),\n",
       " ('no_sentiment[0]',\n",
       "  'I have used Norton products in the past and I am familiar with them.'),\n",
       " ('no_sentiment[0]', 'I bought NIS 2004 recently to try it out.'),\n",
       " ('Installation[-2]', 'After 4 attempted installs, I have finally given up.'),\n",
       " ('no_sentiment[0]',\n",
       "  'I am thankful that I have Roxio GOBACK, I had to use it 3 of the 4 times.')]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from icecream import ic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from icecream import ic\n",
    "\n",
    "\n",
    "basepath = os.getcwd()\n",
    "raw_txt_dir = \"data\"\n",
    "full_path = os.path.join(basepath, raw_txt_dir)\n",
    "\n",
    "def parsefile(file):\n",
    "    try:\n",
    "        with open(file, mode=\"r\") as f:\n",
    "            contents = f.read()\n",
    "            return contents\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "        \n",
    "\n",
    "def split_stream(stream):\n",
    "    try:\n",
    "        split_reviews = stream.split(\"\\n\")\n",
    "        review_tuples = []\n",
    "        for sent in split_reviews:\n",
    "            sent = sent.strip()\n",
    "            if sent==\"\":\n",
    "                continue\n",
    "            split_sent = sent.split(\"##\")\n",
    "            assert len(split_sent)==2, f\"This sentence review does not split into two: {sent}\"\n",
    "            split_sent[0] = split_sent[0].strip()\n",
    "            if split_sent[0] == \"\":\n",
    "                split_sent[0] = \"no_sentiment[0]\"\n",
    "            review_tuples.append((split_sent[0], split_sent[1]))\n",
    "        return review_tuples \n",
    "    except AssertionError as e:\n",
    "        print(e) \n",
    "    \n",
    "\n",
    "def remove_annotation(stream:str) -> str:\n",
    "    pattern = r\"\\*(.*)\\*\"\n",
    "    match = re.search(pattern, stream, re.DOTALL)\n",
    "    if match:\n",
    "        stream = stream[:match.start()] + stream[match.end():]\n",
    "        return stream\n",
    "    return stream\n",
    "\n",
    "def remove_titles(stream:str) -> str:\n",
    "    pattern = r\"(\\[t\\].*)\"\n",
    "    return recurse_remove(stream=stream, pattern=pattern)\n",
    "\n",
    "def recurse_remove(stream, pattern):\n",
    "    match = re.search(pattern, stream)\n",
    "    if match is None:\n",
    "        return stream\n",
    "    else:\n",
    "        stream = stream[:match.start()] + stream[match.end():]\n",
    "        return recurse_remove(stream, pattern)\n",
    "\n",
    "def preprocess_pipeline(filepath:str) -> list[str]:\n",
    "    try:\n",
    "        raw_text = parsefile(filepath)\n",
    "        clean_of_annotations_text = remove_annotation(stream=raw_text)\n",
    "        clean_of_review_titles_text = remove_titles(stream=clean_of_annotations_text)\n",
    "        tuples = split_stream(clean_of_review_titles_text)\n",
    "        return tuples\n",
    "    except AssertionError as e:\n",
    "        print(e)\n",
    "\n",
    "def read_files():\n",
    "    for folder in os.listdir(full_path):\n",
    "        try:\n",
    "            for file in os.listdir(os.path.join(full_path, folder)):\n",
    "                if str(file) != \"Readme.txt\" and str(file) != \".DS_Store\":\n",
    "                    try:\n",
    "                        preprocessed_tuples = preprocess_pipeline(os.path.join(full_path, folder, file))\n",
    "                        return preprocessed_tuples\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "        except NotADirectoryError:\n",
    "            pass\n",
    "\n",
    "path = \"/Users/jossinger/Dropbox/Studies/Bath_Artificial_Intelligence/Course Material/6_NLP/Programming/Submission/data/Reviews-9-products/norton.txt\"\n",
    "preprocess_pipeline(path)[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
